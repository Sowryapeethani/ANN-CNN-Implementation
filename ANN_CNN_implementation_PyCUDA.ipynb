{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-12T21:48:30.767226Z",
          "iopub.execute_input": "2024-11-12T21:48:30.767764Z",
          "iopub.status.idle": "2024-11-12T21:48:42.475088Z",
          "shell.execute_reply.started": "2024-11-12T21:48:30.767583Z",
          "shell.execute_reply": "2024-11-12T21:48:42.474076Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ1PZfK0uAnw",
        "outputId": "033f5333-fd12-41b3-ec4f-e38093d3acf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.7 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.15-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Downloading pytools-2024.1.15-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.6/88.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1.2-cp310-cp310-linux_x86_64.whl size=660546 sha256=0722942047909d6e4ee95ad07bdc179b6aa6c82f84be80460295f28d94791f3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/63/40/4bf006182f942d3516b71bb2ff3b57ccbdb8b2c0ee81882b6e\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.6 pycuda-2024.1.2 pytools-2024.1.15\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "LAVpS8-4iB0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PyCuda Modules\n",
        "import pycuda\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.driver as drv\n",
        "import pycuda.gpuarray as gpuarray\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "#Numerical processing and plotting libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Utility functions and metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from typing import Tuple, Optional\n",
        "import contextlib\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-12T21:48:42.477165Z",
          "iopub.execute_input": "2024-11-12T21:48:42.477502Z",
          "iopub.status.idle": "2024-11-12T21:48:42.483697Z",
          "shell.execute_reply.started": "2024-11-12T21:48:42.477469Z",
          "shell.execute_reply": "2024-11-12T21:48:42.482822Z"
        },
        "id": "5OPtZYGGuAny"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "S = np.array([[[1, 1, 1, 1, 1],\n",
        "                    [1, 0, 0, 0, 0],\n",
        "                    [1, 1, 1, 1, 1],\n",
        "                    [0, 0, 0, 0, 1],\n",
        "                    [1, 1, 1, 1, 1]],\n",
        "                   [[0, 1, 1, 1, 0],\n",
        "                    [1, 0, 0, 0, 0],\n",
        "                    [0, 1, 1, 1, 0],\n",
        "                    [0, 0, 0, 0, 1],\n",
        "                    [0, 1, 1, 1, 0]],\n",
        "                   [[0, 1, 1, 1, 1],\n",
        "                    [1, 0, 0, 0, 0],\n",
        "                    [0, 1, 1, 1, 0],\n",
        "                    [0, 0, 0, 0, 1],\n",
        "                    [1, 1, 1, 1, 0]],\n",
        "                   [[0, 1, 1, 1, 1],\n",
        "                    [1, 0, 0, 0, 0],\n",
        "                    [0, 1, 1, 1, 0],\n",
        "                    [1, 0, 0, 0, 1],\n",
        "                    [1, 1, 1, 1, 0]],\n",
        "                   [[0, 1, 1, 1, 0],\n",
        "                    [1, 0, 0, 0, 1],\n",
        "                    [0, 1, 1, 1, 0],\n",
        "                    [1, 0, 0, 0, 1],\n",
        "                    [1, 1, 1, 1, 0]],\n",
        "                   [[0, 1, 1, 1, 1],\n",
        "                    [1, 0, 0, 0, 0],\n",
        "                    [0, 1, 1, 1, 0],\n",
        "                    [0, 0, 0, 0, 1],\n",
        "                    [1, 1, 1, 1, 0]],\n",
        "                   [[1, 1, 1, 1, 0],\n",
        "                    [1, 0, 0, 0, 0],\n",
        "                    [1, 1, 1, 1, 0],\n",
        "                    [0, 0, 0, 1, 0],\n",
        "                    [1, 1, 1, 1, 0]],\n",
        "                   [[0, 1, 1, 1, 1],\n",
        "                    [0, 1, 0, 0, 0],\n",
        "                    [0, 1, 1, 1, 1],\n",
        "                    [0, 0, 0, 0, 1],\n",
        "                    [0, 1, 1, 1, 1]],\n",
        "                   [[0, 1, 1, 1, 0],\n",
        "                    [0, 1, 0, 0, 0],\n",
        "                    [0, 1, 1, 1, 0],\n",
        "                    [0, 0, 0, 1, 0],\n",
        "                    [0, 1, 1, 1, 0]],\n",
        "                   [[1, 1, 1, 0, 0],\n",
        "                    [1, 0, 0, 0, 0],\n",
        "                    [1, 1, 1, 0, 0],\n",
        "                    [0, 0, 1, 0, 0],\n",
        "                    [1, 1, 1, 0, 0]]]\n",
        "                 ).reshape(-1, 25)\n",
        "\n",
        "H = np.array([\n",
        "                   [[1, 0, 0, 0, 1],\n",
        "                    [1, 0, 0, 0, 1],\n",
        "                    [1, 1, 1, 1, 1],\n",
        "                    [1, 0, 0, 0, 1],\n",
        "                    [1, 0, 0, 0, 1]],\n",
        "\n",
        "                   [[1, 0, 0, 0, 1],\n",
        "                    [1, 0, 1, 0, 1],\n",
        "                    [1, 1, 1, 1, 1],\n",
        "                    [1, 0, 1, 0, 1],\n",
        "                    [1, 0, 0, 0, 1]],\n",
        "\n",
        "                   [[1, 0, 0, 0, 1],\n",
        "                    [1, 1, 0, 1, 1],\n",
        "                    [1, 1, 1, 1, 1],\n",
        "                    [1, 1, 0, 1, 1],\n",
        "                    [1, 0, 0, 0, 1]],\n",
        "\n",
        "                   [[1, 0, 0, 1, 1],\n",
        "                    [1, 0, 0, 0, 1],\n",
        "                    [1, 1, 1, 1, 1],\n",
        "                    [1, 0, 0, 0, 1],\n",
        "                    [1, 1, 0, 0, 1]],\n",
        "\n",
        "                   [[1, 0, 0, 0, 1],\n",
        "                    [1, 0, 0, 1, 1],\n",
        "                    [1, 1, 1, 1, 1],\n",
        "                    [1, 1, 0, 0, 1],\n",
        "                    [1, 0, 0, 0, 1]],\n",
        "\n",
        "                   [[1, 0, 0, 0, 1],\n",
        "                    [1, 1, 0, 0, 1],\n",
        "                    [1, 1, 1, 1, 1],\n",
        "                    [1, 0, 0, 1, 1],\n",
        "                    [1, 0, 0, 0, 1]],\n",
        "\n",
        "                   [[1, 0, 0, 0, 1],\n",
        "                    [1, 0, 0, 0, 1],\n",
        "                    [1, 1, 1, 1, 1],\n",
        "                    [1, 0, 0, 0, 1],\n",
        "                    [1, 0, 0, 1, 1]],\n",
        "\n",
        "                   [[1, 0, 0, 1, 1],\n",
        "                    [1, 0, 0, 0, 1],\n",
        "                    [1, 1, 1, 1, 1],\n",
        "                    [1, 0, 0, 1, 1],\n",
        "                    [1, 0, 0, 0, 1]],\n",
        "\n",
        "                   [[1, 0, 0, 0, 1],\n",
        "                    [1, 0, 1, 0, 1],\n",
        "                    [1, 1, 1, 1, 1],\n",
        "                    [1, 0, 0, 0, 1],\n",
        "                    [1, 0, 0, 1, 1]],\n",
        "\n",
        "                   [[1, 0, 0, 0, 1],\n",
        "                    [1, 1, 0, 1, 1],\n",
        "                    [1, 1, 1, 1, 1],\n",
        "                    [1, 1, 0, 0, 1],\n",
        "                    [1, 0, 0, 0, 1]]\n",
        "                 ]).reshape(-1, 25)\n",
        "\n",
        "A = np.array([\n",
        "                      [[0, 0, 1, 0, 0],\n",
        "                      [0, 1, 0, 1, 0],\n",
        "                      [0, 1, 1, 1, 0],\n",
        "                      [0, 1, 0, 1, 0],\n",
        "                      [0, 1, 0, 1, 0]],\n",
        "\n",
        "                      [[0, 0, 1, 0, 0],\n",
        "                      [0, 1, 1, 1, 0],\n",
        "                      [1, 0, 0, 0, 1],\n",
        "                      [0, 0, 0, 0, 0],\n",
        "                      [0, 0, 0, 0, 0]],\n",
        "\n",
        "                      [[0, 0, 0, 0, 0],\n",
        "                      [0, 0, 0, 0, 0],\n",
        "                      [0, 0, 1, 0, 0],\n",
        "                      [0, 1, 1, 1, 0],\n",
        "                      [1, 0, 0, 0, 1]],\n",
        "\n",
        "                      [[0, 1, 0, 0, 0],\n",
        "                      [1, 0, 1, 0, 0],\n",
        "                      [1, 1, 1, 0, 0],\n",
        "                      [1, 0, 1, 0, 0],\n",
        "                      [1, 0, 1, 0, 0]],\n",
        "\n",
        "                      [[0, 0, 0, 1, 0],\n",
        "                      [0, 0, 1, 0, 1],\n",
        "                      [0, 0, 1, 1, 1],\n",
        "                      [0, 0, 1, 0, 1],\n",
        "                      [0, 0, 1, 0, 1]],\n",
        "\n",
        "                      [[0, 0, 1, 1, 0],\n",
        "                      [0, 1, 0, 0, 1],\n",
        "                      [0, 1, 1, 1, 1],\n",
        "                      [0, 1, 0, 0, 0],\n",
        "                      [0, 1, 0, 0, 1]],\n",
        "\n",
        "                      [[0, 1, 1, 0, 0],\n",
        "                      [1, 0, 0, 1, 0],\n",
        "                      [1, 1, 1, 1, 0],\n",
        "                      [1, 0, 0, 1, 0],\n",
        "                      [1, 0, 0, 1, 0]],\n",
        "\n",
        "                      [[0, 1, 0, 0, 0],\n",
        "                      [1, 0, 1, 0, 0],\n",
        "                      [1, 1, 1, 0, 0],\n",
        "                      [1, 0, 1, 0, 0],\n",
        "                      [0, 0, 0, 0, 0]],\n",
        "\n",
        "                      [[0, 0, 0, 1, 0],\n",
        "                      [0, 0, 1, 0, 1],\n",
        "                      [0, 0, 1, 1, 1],\n",
        "                      [0, 0, 1, 0, 1],\n",
        "                      [0, 0, 0, 0, 0]],\n",
        "\n",
        "                      [[0, 0, 0, 0, 0],\n",
        "                      [0, 0, 1, 0, 0],\n",
        "                      [0, 1, 1, 1, 0],\n",
        "                      [1, 0, 0, 0, 1],\n",
        "                      [0, 0, 0, 0, 0]]\n",
        "                  ]).reshape(-1, 25)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-12T21:48:42.484766Z",
          "iopub.execute_input": "2024-11-12T21:48:42.485049Z",
          "iopub.status.idle": "2024-11-12T21:48:42.501527Z",
          "shell.execute_reply.started": "2024-11-12T21:48:42.485019Z",
          "shell.execute_reply": "2024-11-12T21:48:42.500716Z"
        },
        "id": "naLV27GfuAn0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(A[0].reshape(5, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "ivY8Y5qCSD3N",
        "outputId": "c50b6317-9ccc-417e-82eb-10d97b5e6eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c505605ad40>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(H[0].reshape(5, 5))"
      ],
      "metadata": {
        "id": "OIKSdX8VTKd-",
        "outputId": "fd345bfd-de50-4cf5-9869-ee5bc704924d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c505604bd00>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(S[0].reshape(5, 5))"
      ],
      "metadata": {
        "id": "BHrCcPQKTNLE",
        "outputId": "ee6bdb94-ebee-4762-e40e-4f27f1157a2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c505609a4a0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "labels = []\n",
        "\n",
        "data_sources = [S, H, A]\n",
        "for label, data in enumerate(data_sources):\n",
        "    dataset.append(data)\n",
        "    labels.extend([label] * len(data))\n",
        "\n",
        "dataset = np.concatenate(dataset, axis=0)\n",
        "labels = np.array(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, train_size = 0.8)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-12T21:48:42.550252Z",
          "iopub.execute_input": "2024-11-12T21:48:42.550606Z",
          "iopub.status.idle": "2024-11-12T21:48:42.558489Z",
          "shell.execute_reply.started": "2024-11-12T21:48:42.550572Z",
          "shell.execute_reply": "2024-11-12T21:48:42.557653Z"
        },
        "id": "DvnJJVkPuAn2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mod = SourceModule(\"\"\"\n",
        "__device__ inline int get_offset(int row, int col, int width) {\n",
        "    return row * width + col;\n",
        "}\n",
        "\n",
        "__device__ inline float relu(float x) {\n",
        "    return fmaxf(0.0f, x);\n",
        "}\n",
        "\n",
        "__device__ inline float relu_derivative(float x) {\n",
        "    return x > 0.0f ? 1.0f : 0.0f;\n",
        "}\n",
        "\n",
        "__global__ void forward(const float* input, const float* w1, const float* w2,\n",
        "                       float* z1, float* z2,\n",
        "                       const int input_size, const int hidden_size,\n",
        "                       const int output_size, const int batch_size) {\n",
        "    const int batch_idx = blockIdx.x;\n",
        "    const int thread_idx = threadIdx.x;\n",
        "\n",
        "    if (thread_idx < hidden_size) {\n",
        "        float sum = 0.0f;\n",
        "        const int hidden_offset = get_offset(batch_idx, thread_idx, hidden_size);\n",
        "\n",
        "        #pragma unroll 4\n",
        "        for (int i = 0; i < input_size; i++) {\n",
        "            sum += input[get_offset(batch_idx, i, input_size)] *\n",
        "                   w1[get_offset(i, thread_idx, hidden_size)];\n",
        "        }\n",
        "\n",
        "        z1[hidden_offset] = relu(sum);\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (thread_idx < output_size) {\n",
        "        float sum = 0.0f;\n",
        "        const int output_offset = get_offset(batch_idx, thread_idx, output_size);\n",
        "\n",
        "        #pragma unroll 4\n",
        "        for (int j = 0; j < hidden_size; j++) {\n",
        "            sum += z1[get_offset(batch_idx, j, hidden_size)] *\n",
        "                   w2[get_offset(j, thread_idx, output_size)];\n",
        "        }\n",
        "\n",
        "        z2[output_offset] = sum;  // No activation for output layer\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void backprop(const float* input, const float* z1, const float* z2,\n",
        "                        const float* target, float* w1, float* w2,\n",
        "                        const int input_size, const int hidden_size,\n",
        "                        const int output_size, const int batch_size,\n",
        "                        const float learning_rate) {\n",
        "    const int batch_idx = blockIdx.x;\n",
        "    const int thread_idx = threadIdx.x;\n",
        "\n",
        "    if (thread_idx < output_size) {\n",
        "        const int output_offset = get_offset(batch_idx, thread_idx, output_size);\n",
        "        const float delta2 = z2[output_offset] - target[output_offset];\n",
        "\n",
        "        #pragma unroll 4\n",
        "        for (int j = 0; j < hidden_size; j++) {\n",
        "            const float gradient = delta2 * z1[get_offset(batch_idx, j, hidden_size)];\n",
        "            atomicAdd(&w2[get_offset(j, thread_idx, output_size)],\n",
        "                     -learning_rate * gradient);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (thread_idx < hidden_size) {\n",
        "        float delta1 = 0.0f;\n",
        "        const int hidden_offset = get_offset(batch_idx, thread_idx, hidden_size);\n",
        "\n",
        "        #pragma unroll 4\n",
        "        for (int k = 0; k < output_size; k++) {\n",
        "            const float output_error = z2[get_offset(batch_idx, k, output_size)] -\n",
        "                                     target[get_offset(batch_idx, k, output_size)];\n",
        "            delta1 += output_error * w2[get_offset(thread_idx, k, output_size)];\n",
        "        }\n",
        "\n",
        "        delta1 *= relu_derivative(z1[hidden_offset]);\n",
        "\n",
        "        #pragma unroll 4\n",
        "        for (int i = 0; i < input_size; i++) {\n",
        "            const float gradient = delta1 * input[get_offset(batch_idx, i, input_size)];\n",
        "            atomicAdd(&w1[get_offset(i, thread_idx, hidden_size)],\n",
        "                     -learning_rate * gradient);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "forward_kernel = mod.get_function(\"forward\")\n",
        "backprop_kernel = mod.get_function(\"backprop\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-12T21:48:42.601327Z",
          "iopub.execute_input": "2024-11-12T21:48:42.601711Z",
          "iopub.status.idle": "2024-11-12T21:48:42.611264Z",
          "shell.execute_reply.started": "2024-11-12T21:48:42.601660Z",
          "shell.execute_reply": "2024-11-12T21:48:42.610286Z"
        },
        "id": "zZCPiTTkuAn4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN:\n",
        "    def __init__(self,\n",
        "                 input_size: int = 25,\n",
        "                 hidden_size: int = 10,\n",
        "                 output_size: int = 3,\n",
        "                 learning_rate: float = 0.01):\n",
        "        \"\"\"\n",
        "        Initialize the Neural Network with GPU support.\n",
        "\n",
        "        Args:\n",
        "            input_size: Number of input features\n",
        "            hidden_size: Number of neurons in hidden layer\n",
        "            output_size: Number of output classes\n",
        "            learning_rate: Learning rate for gradient descent\n",
        "        \"\"\"\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Initialize weights using He initialization\n",
        "        self.w1 = np.random.randn(input_size, hidden_size).astype(np.float32) * np.sqrt(2.0 / input_size)\n",
        "        self.w2 = np.random.randn(hidden_size, output_size).astype(np.float32) * np.sqrt(2.0 / hidden_size)\n",
        "\n",
        "        # Load CUDA kernels\n",
        "        self.forward_kernel = mod.get_function(\"forward\")\n",
        "        self.backprop_kernel = mod.get_function(\"backprop\")\n",
        "\n",
        "        # Transfer weights to GPU\n",
        "        self.w1_gpu = gpuarray.to_gpu(self.w1)\n",
        "        self.w2_gpu = gpuarray.to_gpu(self.w2)\n",
        "\n",
        "        # Set block and grid dimensions\n",
        "        self.block_dim = (max(self.hidden_size, self.output_size), 1, 1)\n",
        "\n",
        "    @staticmethod\n",
        "    def softmax(x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Compute softmax values for each set of scores in x.\n",
        "        Uses numerically stable computation.\n",
        "        \"\"\"\n",
        "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    @contextlib.contextmanager\n",
        "    def gpu_arrays(self, batch_size: int, include_targets: bool = True) -> Tuple[gpuarray.GPUArray, ...]:\n",
        "        \"\"\"\n",
        "        Context manager for GPU array allocation and cleanup.\n",
        "        \"\"\"\n",
        "        arrays = []\n",
        "        try:\n",
        "            # Allocate GPU arrays\n",
        "            z1_gpu = gpuarray.zeros((batch_size, self.hidden_size), dtype=np.float32)\n",
        "            z2_gpu = gpuarray.zeros((batch_size, self.output_size), dtype=np.float32)\n",
        "            arrays.extend([z1_gpu, z2_gpu])\n",
        "\n",
        "            yield arrays\n",
        "        finally:\n",
        "            # Clean up GPU memory\n",
        "            for array in arrays:\n",
        "                array.gpudata.free()\n",
        "\n",
        "    def train_batch(self, batch_x: np.ndarray, batch_y: np.ndarray) -> None:\n",
        "        \"\"\"\n",
        "        Train the network on a single batch of data.\n",
        "\n",
        "        Args:\n",
        "            batch_x: Input data batch\n",
        "            batch_y: Target labels batch (one-hot encoded)\n",
        "        \"\"\"\n",
        "        batch_size = len(batch_x)\n",
        "        grid_dim = (batch_size, 1, 1)\n",
        "\n",
        "        # Transfer batch data to GPU\n",
        "        inputs_gpu = gpuarray.to_gpu(batch_x.astype(np.float32))\n",
        "        targets_gpu = gpuarray.to_gpu(batch_y.astype(np.float32))\n",
        "\n",
        "        with self.gpu_arrays(batch_size) as [z1_gpu, z2_gpu]:\n",
        "            # Forward pass\n",
        "            self.forward_kernel(inputs_gpu, self.w1_gpu, self.w2_gpu, z1_gpu, z2_gpu,\n",
        "                              np.int32(self.input_size), np.int32(self.hidden_size),\n",
        "                              np.int32(self.output_size), np.int32(batch_size),\n",
        "                              block=self.block_dim, grid=grid_dim)\n",
        "\n",
        "            # Apply softmax and update z2_gpu\n",
        "            outputs = self.softmax(z2_gpu.get())\n",
        "            z2_gpu = gpuarray.to_gpu(outputs.astype(np.float32))\n",
        "\n",
        "            # Backward pass\n",
        "            self.backprop_kernel(inputs_gpu, z1_gpu, z2_gpu, targets_gpu,\n",
        "                               self.w1_gpu, self.w2_gpu,\n",
        "                               np.int32(self.input_size), np.int32(self.hidden_size),\n",
        "                               np.int32(self.output_size), np.int32(batch_size),\n",
        "                               np.float32(self.learning_rate),\n",
        "                               block=self.block_dim, grid=grid_dim)\n",
        "\n",
        "        # Clean up input/target GPU arrays\n",
        "        inputs_gpu.gpudata.free()\n",
        "        targets_gpu.gpudata.free()\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Make predictions for the input data.\n",
        "\n",
        "        Args:\n",
        "            X: Input data\n",
        "\n",
        "        Returns:\n",
        "            Probability distributions over classes\n",
        "        \"\"\"\n",
        "        batch_size = len(X)\n",
        "        grid_dim = (batch_size, 1, 1)\n",
        "\n",
        "        inputs_gpu = gpuarray.to_gpu(X.astype(np.float32))\n",
        "\n",
        "        with self.gpu_arrays(batch_size) as [z1_gpu, z2_gpu]:\n",
        "            self.forward_kernel(inputs_gpu, self.w1_gpu, self.w2_gpu, z1_gpu, z2_gpu,\n",
        "                              np.int32(self.input_size), np.int32(self.hidden_size),\n",
        "                              np.int32(self.output_size), np.int32(batch_size),\n",
        "                              block=self.block_dim, grid=grid_dim)\n",
        "\n",
        "            outputs = self.softmax(z2_gpu.get())\n",
        "\n",
        "        inputs_gpu.gpudata.free()\n",
        "        return outputs\n",
        "\n",
        "def train_and_evaluate(X_train: np.ndarray,\n",
        "                      y_train: np.ndarray,\n",
        "                      X_test: np.ndarray,\n",
        "                      y_test: np.ndarray,\n",
        "                      epochs: int = 100,\n",
        "                      batch_size: int = 24,\n",
        "                      validation_interval: int = 10) -> ANN:\n",
        "    \"\"\"\n",
        "    Train the neural network and evaluate its performance.\n",
        "\n",
        "    Args:\n",
        "        X_train: Training data\n",
        "        y_train: Training labels\n",
        "        X_test: Test data\n",
        "        y_test: Test labels\n",
        "        epochs: Number of training epochs\n",
        "        batch_size: Size of training batches\n",
        "        validation_interval: Interval for computing training accuracy\n",
        "\n",
        "    Returns:\n",
        "        Trained neural network\n",
        "    \"\"\"\n",
        "    net = ANN(input_size=25, hidden_size=10, output_size=3)\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    y_train_onehot = np.zeros((len(y_train), 3))\n",
        "    y_train_onehot[np.arange(len(y_train)), y_train] = 1\n",
        "\n",
        "    n_batches = len(X_train) // batch_size\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Shuffle training data\n",
        "        indices = np.random.permutation(len(X_train))\n",
        "        X_train_shuffled = X_train[indices]\n",
        "        y_train_shuffled = y_train_onehot[indices]\n",
        "\n",
        "        # Train on batches\n",
        "        for batch in range(n_batches):\n",
        "            start_idx = batch * batch_size\n",
        "            end_idx = start_idx + batch_size\n",
        "            batch_x = X_train_shuffled[start_idx:end_idx]\n",
        "            batch_y = y_train_shuffled[start_idx:end_idx]\n",
        "            net.train_batch(batch_x, batch_y)\n",
        "\n",
        "        # Compute and print training accuracy at intervals\n",
        "        if (epoch + 1) % validation_interval == 0:\n",
        "            train_preds = np.argmax(net.predict(X_train), axis=1)\n",
        "            train_acc = accuracy_score(y_train, train_preds)\n",
        "            print(f\"Epoch {epoch + 1}, Training Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_preds = np.argmax(net.predict(X_test), axis=1)\n",
        "    test_acc = accuracy_score(y_test, test_preds)\n",
        "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    return net"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-12T21:48:42.612506Z",
          "iopub.execute_input": "2024-11-12T21:48:42.612835Z",
          "iopub.status.idle": "2024-11-12T21:48:42.638800Z",
          "shell.execute_reply.started": "2024-11-12T21:48:42.612802Z",
          "shell.execute_reply": "2024-11-12T21:48:42.637931Z"
        },
        "id": "oVikbB25uAn4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_and_evaluate(X_train, y_train, X_test, y_test, epochs=50, batch_size=24)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-12T21:48:42.639844Z",
          "iopub.execute_input": "2024-11-12T21:48:42.640174Z",
          "iopub.status.idle": "2024-11-12T21:48:42.690205Z",
          "shell.execute_reply.started": "2024-11-12T21:48:42.640143Z",
          "shell.execute_reply": "2024-11-12T21:48:42.689260Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YlY3SbKuAn4",
        "outputId": "332c762d-70fc-4d60-e270-0552d27ff9f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 1228.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Training Accuracy: 0.6667\n",
            "Epoch 20, Training Accuracy: 0.8333\n",
            "Epoch 30, Training Accuracy: 0.9583\n",
            "Epoch 40, Training Accuracy: 1.0000\n",
            "Epoch 50, Training Accuracy: 1.0000\n",
            "Test Accuracy: 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mod = SourceModule(\"\"\"\n",
        "__global__ void conv2d(float *input, float *filters, float *output,\n",
        "                      int batch_size, int height, int width, int channels,\n",
        "                      int num_filters, int kernel_size, int output_height, int output_width) {\n",
        "    int batch_idx = blockIdx.x;\n",
        "    int filter_idx = blockIdx.y;\n",
        "    int out_y = threadIdx.x;\n",
        "    int out_x = threadIdx.y;\n",
        "\n",
        "    if (out_y < output_height && out_x < output_width) {\n",
        "        float sum = 0.0f;\n",
        "\n",
        "        for (int c = 0; c < channels; c++) {\n",
        "            for (int ky = 0; ky < kernel_size; ky++) {\n",
        "                for (int kx = 0; kx < kernel_size; kx++) {\n",
        "                    int in_y = out_y + ky;\n",
        "                    int in_x = out_x + kx;\n",
        "\n",
        "                    if (in_y < height && in_x < width) {\n",
        "                        int input_idx = batch_idx * (height * width * channels) +\n",
        "                                      c * (height * width) +\n",
        "                                      in_y * width + in_x;\n",
        "                        int filter_idx_full = filter_idx * (channels * kernel_size * kernel_size) +\n",
        "                                            c * (kernel_size * kernel_size) +\n",
        "                                            ky * kernel_size + kx;\n",
        "\n",
        "                        sum += input[input_idx] * filters[filter_idx_full];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        int output_idx = batch_idx * (num_filters * output_height * output_width) +\n",
        "                        filter_idx * (output_height * output_width) +\n",
        "                        out_y * output_width + out_x;\n",
        "        output[output_idx] = fmaxf(0.0f, sum);  // ReLU activation\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void max_pool2d(float *input, float *output,\n",
        "                          int batch_size, int height, int width, int channels,\n",
        "                          int pool_size, int output_height, int output_width) {\n",
        "    int batch_idx = blockIdx.x;\n",
        "    int channel = blockIdx.y;\n",
        "    int out_y = threadIdx.x;\n",
        "    int out_x = threadIdx.y;\n",
        "\n",
        "    if (out_y < output_height && out_x < output_width) {\n",
        "        float max_val = -1e10f;\n",
        "\n",
        "        for (int py = 0; py < pool_size; py++) {\n",
        "            for (int px = 0; px < pool_size; px++) {\n",
        "                int in_y = out_y * pool_size + py;\n",
        "                int in_x = out_x * pool_size + px;\n",
        "\n",
        "                if (in_y < height && in_x < width) {\n",
        "                    int input_idx = batch_idx * (channels * height * width) +\n",
        "                                  channel * (height * width) +\n",
        "                                  in_y * width + in_x;\n",
        "                    max_val = fmaxf(max_val, input[input_idx]);\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        int output_idx = batch_idx * (channels * output_height * output_width) +\n",
        "                        channel * (output_height * output_width) +\n",
        "                        out_y * output_width + out_x;\n",
        "        output[output_idx] = max_val;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void fc_forward(float *input, float *weights, float *output,\n",
        "                          int batch_size, int input_size, int output_size) {\n",
        "    int batch_idx = blockIdx.x;\n",
        "    int neuron_idx = threadIdx.x;\n",
        "\n",
        "    if (neuron_idx < output_size) {\n",
        "        float sum = 0.0f;\n",
        "        for (int i = 0; i < input_size; i++) {\n",
        "            sum += input[batch_idx * input_size + i] * weights[i * output_size + neuron_idx];\n",
        "        }\n",
        "        output[batch_idx * output_size + neuron_idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void conv2d_backward(float *d_output, float *filters, float *d_input,\n",
        "                               int batch_size, int height, int width, int channels,\n",
        "                               int num_filters, int kernel_size, int output_height, int output_width) {\n",
        "    int batch_idx = blockIdx.x;\n",
        "    int channel = blockIdx.y;\n",
        "    int in_y = threadIdx.x;\n",
        "    int in_x = threadIdx.y;\n",
        "\n",
        "    if (in_y < height && in_x < width) {\n",
        "        float sum = 0.0f;\n",
        "\n",
        "        for (int f = 0; f < num_filters; f++) {\n",
        "            for (int ky = 0; ky < kernel_size; ky++) {\n",
        "                for (int kx = 0; kx < kernel_size; kx++) {\n",
        "                    int out_y = in_y - ky;\n",
        "                    int out_x = in_x - kx;\n",
        "\n",
        "                    if (out_y >= 0 && out_y < output_height && out_x >= 0 && out_x < output_width) {\n",
        "                        int d_output_idx = batch_idx * (num_filters * output_height * output_width) +\n",
        "                                         f * (output_height * output_width) +\n",
        "                                         out_y * output_width + out_x;\n",
        "                        int filter_idx = f * (channels * kernel_size * kernel_size) +\n",
        "                                       channel * (kernel_size * kernel_size) +\n",
        "                                       ky * kernel_size + kx;\n",
        "\n",
        "                        sum += d_output[d_output_idx] * filters[filter_idx];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        int d_input_idx = batch_idx * (channels * height * width) +\n",
        "                         channel * (height * width) +\n",
        "                         in_y * width + in_x;\n",
        "        d_input[d_input_idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void conv2d_update_weights(float *input, float *d_output, float *d_weights,\n",
        "                                    int batch_size, int height, int width, int channels,\n",
        "                                    int num_filters, int kernel_size, int output_height, int output_width) {\n",
        "    int filter_idx = blockIdx.x;\n",
        "    int c = blockIdx.y;\n",
        "    int ky = threadIdx.x;\n",
        "    int kx = threadIdx.y;\n",
        "\n",
        "    if (ky < kernel_size && kx < kernel_size) {\n",
        "        float sum = 0.0f;\n",
        "\n",
        "        for (int b = 0; b < batch_size; b++) {\n",
        "            for (int out_y = 0; out_y < output_height; out_y++) {\n",
        "                for (int out_x = 0; out_x < output_width; out_x++) {\n",
        "                    int in_y = out_y + ky;\n",
        "                    int in_x = out_x + kx;\n",
        "\n",
        "                    if (in_y < height && in_x < width) {\n",
        "                        int input_idx = b * (channels * height * width) +\n",
        "                                      c * (height * width) +\n",
        "                                      in_y * width + in_x;\n",
        "                        int d_output_idx = b * (num_filters * output_height * output_width) +\n",
        "                                         filter_idx * (output_height * output_width) +\n",
        "                                         out_y * output_width + out_x;\n",
        "\n",
        "                        sum += input[input_idx] * d_output[d_output_idx];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        int weight_idx = filter_idx * (channels * kernel_size * kernel_size) +\n",
        "                        c * (kernel_size * kernel_size) +\n",
        "                        ky * kernel_size + kx;\n",
        "        d_weights[weight_idx] = sum / batch_size;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void max_pool_backward(float *input, float *d_output, float *d_input,\n",
        "                                int batch_size, int height, int width, int channels,\n",
        "                                int pool_size, int output_height, int output_width) {\n",
        "    int batch_idx = blockIdx.x;\n",
        "    int channel = blockIdx.y;\n",
        "    int in_y = threadIdx.x;\n",
        "    int in_x = threadIdx.y;\n",
        "\n",
        "    if (in_y < height && in_x < width) {\n",
        "        int out_y = in_y / pool_size;\n",
        "        int out_x = in_x / pool_size;\n",
        "\n",
        "        if (out_y < output_height && out_x < output_width) {\n",
        "            int input_idx = batch_idx * (channels * height * width) +\n",
        "                           channel * (height * width) +\n",
        "                           in_y * width + in_x;\n",
        "            int output_idx = batch_idx * (channels * output_height * output_width) +\n",
        "                           channel * (output_height * output_width) +\n",
        "                           out_y * output_width + out_x;\n",
        "            float max_val = -1e10f;\n",
        "            int max_idx_y = -1, max_idx_x = -1;\n",
        "\n",
        "            for (int py = 0; py < pool_size; py++) {\n",
        "                for (int px = 0; px < pool_size; px++) {\n",
        "                    int curr_y = out_y * pool_size + py;\n",
        "                    int curr_x = out_x * pool_size + px;\n",
        "\n",
        "                    if (curr_y < height && curr_x < width) {\n",
        "                        int curr_idx = batch_idx * (channels * height * width) +\n",
        "                                     channel * (height * width) +\n",
        "                                     curr_y * width + curr_x;\n",
        "                        float curr_val = input[curr_idx];\n",
        "\n",
        "                        if (curr_val > max_val) {\n",
        "                            max_val = curr_val;\n",
        "                            max_idx_y = curr_y;\n",
        "                            max_idx_x = curr_x;\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "\n",
        "            if (in_y == max_idx_y && in_x == max_idx_x) {\n",
        "                d_input[input_idx] = d_output[output_idx];\n",
        "            } else {\n",
        "                d_input[input_idx] = 0.0f;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void fc_backward(float *d_output, float *weights, float *d_input,\n",
        "                           int batch_size, int input_size, int output_size) {\n",
        "    int batch_idx = blockIdx.x;\n",
        "    int input_idx = threadIdx.x;\n",
        "\n",
        "    if (input_idx < input_size) {\n",
        "        float sum = 0.0f;\n",
        "        for (int j = 0; j < output_size; j++) {\n",
        "            sum += d_output[batch_idx * output_size + j] * weights[input_idx * output_size + j];\n",
        "        }\n",
        "        d_input[batch_idx * input_size + input_idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void fc_update_weights(float *input, float *d_output, float *d_weights,\n",
        "                                int batch_size, int input_size, int output_size) {\n",
        "    int in_idx = blockIdx.x;\n",
        "    int out_idx = threadIdx.x;\n",
        "\n",
        "    if (in_idx < input_size && out_idx < output_size) {\n",
        "        float sum = 0.0f;\n",
        "        for (int b = 0; b < batch_size; b++) {\n",
        "            sum += input[b * input_size + in_idx] * d_output[b * output_size + out_idx];\n",
        "        }\n",
        "        d_weights[in_idx * output_size + out_idx] = sum / batch_size;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void relu(float *x, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        x[idx] = fmaxf(0.0f, x[idx]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void softmax(float *x, int batch_size, int num_classes) {\n",
        "    int batch_idx = blockIdx.x;\n",
        "    int class_idx = threadIdx.x;\n",
        "\n",
        "    if (class_idx < num_classes) {\n",
        "        __shared__ float max_val;\n",
        "        __shared__ float sum_exp;\n",
        "\n",
        "        // Find max value for numerical stability\n",
        "        if (class_idx == 0) {\n",
        "            max_val = -1e9f;\n",
        "            for (int j = 0; j < num_classes; j++) {\n",
        "                max_val = fmaxf(max_val, x[batch_idx * num_classes + j]);\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        // Calculate exp and sum\n",
        "        float exp_val = expf(x[batch_idx * num_classes + class_idx] - max_val);\n",
        "        x[batch_idx * num_classes + class_idx] = exp_val;\n",
        "\n",
        "        // Use atomic add for sum\n",
        "        atomicAdd(&sum_exp, exp_val);\n",
        "        __syncthreads();\n",
        "\n",
        "        // Normalize\n",
        "        x[batch_idx * num_classes + class_idx] = exp_val / sum_exp;\n",
        "    }\n",
        "}\n",
        "\"\"\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-12T21:48:42.691583Z",
          "iopub.execute_input": "2024-11-12T21:48:42.691947Z",
          "iopub.status.idle": "2024-11-12T21:48:42.707577Z",
          "shell.execute_reply.started": "2024-11-12T21:48:42.691906Z",
          "shell.execute_reply": "2024-11-12T21:48:42.706657Z"
        },
        "id": "iYCWrxgwuAn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad70432-42b5-42cb-dbed-fe213512b69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN:\n",
        "    def __init__(self, learning_rate=0.01):\n",
        "        \"\"\"\n",
        "        Initialize CNN with specified parameters.\n",
        "\n",
        "        Args:\n",
        "            learning_rate (float): Learning rate for gradient descent (default: 0.01)\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If learning_rate is not positive\n",
        "        \"\"\"\n",
        "        if learning_rate <= 0:\n",
        "            raise ValueError(\"Learning rate must be positive\")\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.conv1_filters = 32\n",
        "        self.conv1_size = 3\n",
        "        self.pool_size = 2\n",
        "        self.fc1_size = 10\n",
        "        self.num_classes = 3\n",
        "        self.input_size = 5\n",
        "\n",
        "        # Compute derived dimensions\n",
        "        self.conv1_output_size = self.input_size - self.conv1_size + 1\n",
        "        self.pool1_output_size = self.conv1_output_size // self.pool_size\n",
        "\n",
        "        # Initialize weights with He initialization\n",
        "        scale = np.sqrt(2.0 / (self.conv1_size * self.conv1_size))\n",
        "        conv1_weights = np.random.randn(self.conv1_filters, 1,\n",
        "                                      self.conv1_size, self.conv1_size).astype(np.float32) * scale\n",
        "        self.conv1_weights_gpu = gpuarray.to_gpu(conv1_weights)\n",
        "\n",
        "        fc1_input_size = self.conv1_filters * self.pool1_output_size * self.pool1_output_size\n",
        "        scale = np.sqrt(2.0 / fc1_input_size)\n",
        "        fc1_weights = np.random.randn(fc1_input_size, self.fc1_size).astype(np.float32) * scale\n",
        "        self.fc1_weights_gpu = gpuarray.to_gpu(fc1_weights)\n",
        "\n",
        "        scale = np.sqrt(2.0 / self.fc1_size)\n",
        "        fc2_weights = np.random.randn(self.fc1_size, self.num_classes).astype(np.float32) * scale\n",
        "        self.fc2_weights_gpu = gpuarray.to_gpu(fc2_weights)\n",
        "\n",
        "        # Load CUDA kernels\n",
        "        self._load_cuda_kernels()\n",
        "\n",
        "        # Initialize tracking metrics\n",
        "        self.train_losses = []\n",
        "        self.train_accuracies = []\n",
        "        self.eval_accuracies = []\n",
        "\n",
        "    def _load_cuda_kernels(self):\n",
        "        \"\"\"Load all required CUDA kernel functions.\"\"\"\n",
        "        self.max_pool = mod.get_function(\"max_pool2d\")\n",
        "        self.fc_forward = mod.get_function(\"fc_forward\")\n",
        "        self.conv_forward = mod.get_function(\"conv2d\")\n",
        "        self.conv_backward = mod.get_function(\"conv2d_backward\")\n",
        "        self.conv_update_weights = mod.get_function(\"conv2d_update_weights\")\n",
        "        self.pool_backward = mod.get_function(\"max_pool_backward\")\n",
        "        self.fc_backward = mod.get_function(\"fc_backward\")\n",
        "        self.fc_update_weights = mod.get_function(\"fc_update_weights\")\n",
        "        self.relu = mod.get_function(\"relu\")\n",
        "        self.softmax = mod.get_function(\"softmax\")\n",
        "\n",
        "    def _free_gpu_memory(self, *gpu_arrays):\n",
        "        \"\"\"Safely free GPU memory for multiple arrays.\"\"\"\n",
        "        for arr in gpu_arrays:\n",
        "            if arr is not None and hasattr(arr, 'gpudata'):\n",
        "                arr.gpudata.free()\n",
        "\n",
        "    def backward(self, x_batch, y_batch, output):\n",
        "        \"\"\"\n",
        "        Perform backward pass through the network.\n",
        "\n",
        "        Args:\n",
        "            x_batch: Input batch data\n",
        "            y_batch: Target labels\n",
        "            output: Network output from forward pass\n",
        "        \"\"\"\n",
        "        batch_size = len(x_batch)\n",
        "\n",
        "        # Calculate initial gradient\n",
        "        d_output = output.copy()\n",
        "        d_output[range(batch_size), y_batch] -= 1\n",
        "        d_output /= batch_size\n",
        "\n",
        "        # Initialize GPU arrays\n",
        "        d_fc2_output_gpu = gpuarray.to_gpu(d_output)\n",
        "        d_fc1_output = gpuarray.zeros((batch_size, self.fc1_size), dtype=np.float32)\n",
        "\n",
        "        try:\n",
        "            # Backward pass through FC2\n",
        "            block_dim = (self.fc1_size, 1, 1)\n",
        "            grid_dim = (batch_size, 1, 1)\n",
        "\n",
        "            self.fc_backward(d_fc2_output_gpu, self.fc2_weights_gpu, d_fc1_output,\n",
        "                           np.int32(batch_size), np.int32(self.fc1_size),\n",
        "                           np.int32(self.num_classes),\n",
        "                           block=block_dim, grid=grid_dim)\n",
        "\n",
        "            d_fc2_weights = gpuarray.zeros_like(self.fc2_weights_gpu)\n",
        "\n",
        "            block_dim = (self.num_classes, 1, 1)\n",
        "            grid_dim = (self.fc1_size, 1, 1)\n",
        "\n",
        "            self.fc_update_weights(d_fc1_output, d_fc2_output_gpu, d_fc2_weights,\n",
        "                                 np.int32(batch_size), np.int32(self.fc1_size),\n",
        "                                 np.int32(self.num_classes),\n",
        "                                 block=block_dim, grid=grid_dim)\n",
        "\n",
        "            # Backward pass through pooling layer\n",
        "            d_pool1_output = gpuarray.zeros((batch_size, self.conv1_filters,\n",
        "                                           self.pool1_output_size, self.pool1_output_size),\n",
        "                                          dtype=np.float32)\n",
        "\n",
        "            flattened_size = self.conv1_filters * self.pool1_output_size * self.pool1_output_size\n",
        "\n",
        "            block_dim = (flattened_size, 1, 1)\n",
        "            grid_dim = (batch_size, 1, 1)\n",
        "\n",
        "            self.fc_backward(d_fc1_output, self.fc1_weights_gpu, d_pool1_output,\n",
        "                           np.int32(batch_size), np.int32(flattened_size),\n",
        "                           np.int32(self.fc1_size),\n",
        "                           block=block_dim, grid=grid_dim)\n",
        "\n",
        "            d_fc1_weights = gpuarray.zeros_like(self.fc1_weights_gpu)\n",
        "\n",
        "            block_dim = (self.fc1_size, 1, 1)\n",
        "            grid_dim = (flattened_size, 1, 1)\n",
        "\n",
        "            self.fc_update_weights(d_pool1_output, d_fc1_output, d_fc1_weights,\n",
        "                                 np.int32(batch_size), np.int32(flattened_size),\n",
        "                                 np.int32(self.fc1_size),\n",
        "                                 block=block_dim, grid=grid_dim)\n",
        "\n",
        "            # Backward pass through conv layer\n",
        "            d_conv1_output = gpuarray.zeros((batch_size, self.conv1_filters,\n",
        "                                           self.conv1_output_size, self.conv1_output_size),\n",
        "                                          dtype=np.float32)\n",
        "\n",
        "            block_dim = (self.conv1_output_size, self.conv1_output_size, 1)\n",
        "            grid_dim = (batch_size, self.conv1_filters, 1)\n",
        "\n",
        "            self.pool_backward(d_conv1_output, d_pool1_output, d_conv1_output,\n",
        "                             np.int32(batch_size), np.int32(self.conv1_output_size),\n",
        "                             np.int32(self.conv1_output_size), np.int32(self.conv1_filters),\n",
        "                             np.int32(self.pool_size), np.int32(self.pool1_output_size),\n",
        "                             np.int32(self.pool1_output_size),\n",
        "                             block=block_dim, grid=grid_dim)\n",
        "\n",
        "            d_input = gpuarray.zeros((batch_size, 1, 5, 5), dtype=np.float32)\n",
        "\n",
        "            block_dim = (5, 5, 1)\n",
        "            grid_dim = (batch_size, 1, 1)\n",
        "\n",
        "            self.conv_backward(d_conv1_output, self.conv1_weights_gpu, d_input,\n",
        "                             np.int32(batch_size), np.int32(5), np.int32(5), np.int32(1),\n",
        "                             np.int32(self.conv1_filters), np.int32(self.conv1_size),\n",
        "                             np.int32(self.conv1_output_size), np.int32(self.conv1_output_size),\n",
        "                             block=block_dim, grid=grid_dim)\n",
        "\n",
        "            d_conv1_weights = gpuarray.zeros_like(self.conv1_weights_gpu)\n",
        "\n",
        "            block_dim = (self.conv1_size, self.conv1_size, 1)\n",
        "            grid_dim = (self.conv1_filters, 1, 1)\n",
        "\n",
        "            self.conv_update_weights(d_input, d_conv1_output, d_conv1_weights,\n",
        "                                   np.int32(batch_size), np.int32(5), np.int32(5), np.int32(1),\n",
        "                                   np.int32(self.conv1_filters), np.int32(self.conv1_size),\n",
        "                                   np.int32(self.conv1_output_size), np.int32(self.conv1_output_size),\n",
        "                                   block=block_dim, grid=grid_dim)\n",
        "\n",
        "            # Update weights with gradient descent\n",
        "            self.conv1_weights_gpu -= self.learning_rate * d_conv1_weights\n",
        "            self.fc1_weights_gpu -= self.learning_rate * d_fc1_weights\n",
        "            self.fc2_weights_gpu -= self.learning_rate * d_fc2_weights\n",
        "\n",
        "        finally:\n",
        "            # Clean up GPU memory\n",
        "            self._free_gpu_memory(\n",
        "                d_fc2_output_gpu, d_fc1_output, d_pool1_output,\n",
        "                d_conv1_output, d_input, d_conv1_weights,\n",
        "                d_fc1_weights, d_fc2_weights\n",
        "            )\n",
        "\n",
        "    def compute_loss(self, output, y_batch):\n",
        "        \"\"\"\n",
        "        Compute cross-entropy loss.\n",
        "\n",
        "        Args:\n",
        "            output: Network output\n",
        "            y_batch: Target labels\n",
        "\n",
        "        Returns:\n",
        "            float: Average loss value\n",
        "        \"\"\"\n",
        "        batch_size = len(y_batch)\n",
        "        output_cpu = output.get()\n",
        "        epsilon = 1e-7  # Prevent log(0)\n",
        "        output_cpu = np.clip(output_cpu, epsilon, 1 - epsilon)\n",
        "        log_likelihood = -np.log(output_cpu[range(batch_size), y_batch])\n",
        "        return np.mean(log_likelihood)\n",
        "\n",
        "    def compute_accuracy(self, output, y_batch):\n",
        "        \"\"\"\n",
        "        Compute classification accuracy.\n",
        "\n",
        "        Args:\n",
        "            output: Network output\n",
        "            y_batch: Target labels\n",
        "\n",
        "        Returns:\n",
        "            float: Accuracy value\n",
        "        \"\"\"\n",
        "        predictions = np.argmax(output.get(), axis=1)\n",
        "        return np.mean(predictions == y_batch)\n",
        "\n",
        "    def forward(self, x_batch):\n",
        "        \"\"\"\n",
        "        Perform forward pass through the network.\n",
        "\n",
        "        Args:\n",
        "            x_batch: Input batch data\n",
        "\n",
        "        Returns:\n",
        "            tuple: Network outputs at each layer\n",
        "        \"\"\"\n",
        "        batch_size = len(x_batch)\n",
        "\n",
        "        # Transfer input to GPU\n",
        "        input_gpu = gpuarray.to_gpu(x_batch.astype(np.float32))\n",
        "\n",
        "        try:\n",
        "            # Convolution layer\n",
        "            conv1_output = gpuarray.zeros((batch_size, self.conv1_filters,\n",
        "                                         self.conv1_output_size, self.conv1_output_size),\n",
        "                                        dtype=np.float32)\n",
        "\n",
        "            block_dim = (self.conv1_output_size, self.conv1_output_size, 1)\n",
        "            grid_dim = (batch_size, self.conv1_filters, 1)\n",
        "\n",
        "            self.conv_forward(input_gpu, self.conv1_weights_gpu, conv1_output,\n",
        "                            np.int32(batch_size), np.int32(5), np.int32(5), np.int32(1),\n",
        "                            np.int32(self.conv1_filters), np.int32(self.conv1_size),\n",
        "                            np.int32(self.conv1_output_size), np.int32(self.conv1_output_size),\n",
        "                            block=block_dim, grid=grid_dim)\n",
        "\n",
        "            # Max pooling layer\n",
        "            pool1_output = gpuarray.zeros((batch_size, self.conv1_filters,\n",
        "                                         self.pool1_output_size, self.pool1_output_size),\n",
        "                                        dtype=np.float32)\n",
        "\n",
        "            block_dim = (self.pool1_output_size, self.pool1_output_size, 1)\n",
        "            grid_dim = (batch_size, self.conv1_filters, 1)\n",
        "\n",
        "            self.max_pool(conv1_output, pool1_output,\n",
        "                         np.int32(batch_size), np.int32(self.conv1_output_size),\n",
        "                         np.int32(self.conv1_output_size), np.int32(self.conv1_filters),\n",
        "                         np.int32(self.pool_size), np.int32(self.pool1_output_size),\n",
        "                         np.int32(self.pool1_output_size),\n",
        "                         block=block_dim, grid=grid_dim)\n",
        "\n",
        "            # Flatten pooling output\n",
        "            flattened = pool1_output.reshape(batch_size, -1)\n",
        "\n",
        "            # First fully connected layer\n",
        "            fc1_output = gpuarray.zeros((batch_size, self.fc1_size), dtype=np.float32)\n",
        "\n",
        "            block_dim = (self.fc1_size, 1, 1)\n",
        "            grid_dim = (batch_size, 1, 1)\n",
        "\n",
        "            self.fc_forward(flattened, self.fc1_weights_gpu, fc1_output,\n",
        "                          np.int32(batch_size), np.int32(flattened.shape[1]),\n",
        "                          np.int32(self.fc1_size),\n",
        "                          block=block_dim, grid=grid_dim)\n",
        "\n",
        "            # ReLU activation\n",
        "            self.relu(fc1_output, np.int32(fc1_output.size),\n",
        "                     block=(256, 1, 1), grid=((fc1_output.size + 255) // 256, 1, 1))\n",
        "\n",
        "            # Second fully connected layer (output layer)\n",
        "            output = gpuarray.zeros((batch_size, self.num_classes), dtype=np.float32)\n",
        "\n",
        "            block_dim = (self.num_classes, 1, 1)\n",
        "            grid_dim = (batch_size, 1, 1)\n",
        "\n",
        "            self.fc_forward(fc1_output, self.fc2_weights_gpu, output,\n",
        "                          np.int32(batch_size), np.int32(self.fc1_size),\n",
        "                          np.int32(self.num_classes),\n",
        "                          block=block_dim, grid=grid_dim)\n",
        "\n",
        "            # Softmax activation\n",
        "            # Softmax activation (continued)\n",
        "            self.softmax(output, np.int32(batch_size), np.int32(self.num_classes),\n",
        "                        block=(self.num_classes, 1, 1), grid=(batch_size, 1, 1))\n",
        "\n",
        "            return output, conv1_output, pool1_output, fc1_output\n",
        "\n",
        "        except Exception as e:\n",
        "            self._free_gpu_memory(input_gpu)\n",
        "            raise RuntimeError(f\"Forward pass failed: {str(e)}\")\n",
        "\n",
        "    def train(self, X_train, y_train, X_val=None, y_val=None, epochs=10, batch_size=24):\n",
        "        \"\"\"\n",
        "        Train the CNN using mini-batch gradient descent.\n",
        "\n",
        "        Args:\n",
        "            X_train: Training data\n",
        "            y_train: Training labels\n",
        "            X_val: Validation data (optional)\n",
        "            y_val: Validation labels (optional)\n",
        "            epochs: Number of training epochs (default: 10)\n",
        "            batch_size: Size of mini-batches (default: 24)\n",
        "\n",
        "        Returns:\n",
        "            dict: Training history including losses and accuracies\n",
        "        \"\"\"\n",
        "        if len(X_train) != len(y_train):\n",
        "            raise ValueError(\"X_train and y_train must have the same length\")\n",
        "\n",
        "        if X_val is not None and y_val is not None and len(X_val) != len(y_val):\n",
        "            raise ValueError(\"X_val and y_val must have the same length\")\n",
        "\n",
        "        if batch_size <= 0:\n",
        "            raise ValueError(\"batch_size must be positive\")\n",
        "\n",
        "        if epochs <= 0:\n",
        "            raise ValueError(\"epochs must be positive\")\n",
        "\n",
        "        n_samples = len(X_train)\n",
        "        n_batches = (n_samples + batch_size - 1) // batch_size\n",
        "\n",
        "        history = {\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_acc': []\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            for epoch in tqdm(range(epochs)):\n",
        "                # Shuffle training data\n",
        "                indices = np.random.permutation(n_samples)\n",
        "                X_train = X_train[indices]\n",
        "                y_train = y_train[indices]\n",
        "\n",
        "                epoch_loss = 0\n",
        "                epoch_accuracy = 0\n",
        "\n",
        "                for batch in range(n_batches):\n",
        "                    start_idx = batch * batch_size\n",
        "                    end_idx = min((batch + 1) * batch_size, n_samples)\n",
        "\n",
        "                    x_batch = X_train[start_idx:end_idx]\n",
        "                    y_batch = y_train[start_idx:end_idx]\n",
        "\n",
        "                    # Forward pass\n",
        "                    output, conv1_output, pool1_output, fc1_output = self.forward(x_batch)\n",
        "\n",
        "                    # Compute metrics\n",
        "                    batch_loss = self.compute_loss(output, y_batch)\n",
        "                    batch_accuracy = self.compute_accuracy(output, y_batch)\n",
        "\n",
        "                    epoch_loss += batch_loss * len(x_batch)\n",
        "                    epoch_accuracy += batch_accuracy * len(x_batch)\n",
        "\n",
        "                    # Backward pass\n",
        "                    self.backward(x_batch, y_batch, output.get())\n",
        "\n",
        "                    # Clean up GPU memory\n",
        "                    self._free_gpu_memory(\n",
        "                        conv1_output, pool1_output,\n",
        "                        fc1_output, output\n",
        "                    )\n",
        "\n",
        "                # Compute epoch metrics\n",
        "                epoch_loss /= n_samples\n",
        "                epoch_accuracy /= n_samples\n",
        "\n",
        "                # Update history\n",
        "                history['train_loss'].append(epoch_loss)\n",
        "                history['train_acc'].append(epoch_accuracy)\n",
        "\n",
        "                # Evaluate on validation set if provided\n",
        "                val_accuracy = None\n",
        "                if X_val is not None and y_val is not None:\n",
        "                    val_accuracy = self.evaluate(X_val, y_val, batch_size)\n",
        "                    history['val_acc'].append(val_accuracy)\n",
        "\n",
        "                # Print progress\n",
        "                progress_msg = f\"Epoch {epoch+1} - Accuracy: {epoch_accuracy:.4f}\"\n",
        "                if val_accuracy is not None:\n",
        "                    progress_msg += f\" - Val Accuracy: {val_accuracy:.4f}\"\n",
        "                print(progress_msg)\n",
        "\n",
        "            return history\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Training failed: {str(e)}\")\n",
        "\n",
        "    def evaluate(self, X_test, y_test, batch_size=24):\n",
        "        \"\"\"\n",
        "        Evaluate the CNN on test data.\n",
        "\n",
        "        Args:\n",
        "            X_test: Test data\n",
        "            y_test: Test labels\n",
        "            batch_size: Size of mini-batches (default: 24)\n",
        "\n",
        "        Returns:\n",
        "            float: Test accuracy\n",
        "        \"\"\"\n",
        "        if len(X_test) != len(y_test):\n",
        "            raise ValueError(\"X_test and y_test must have the same length\")\n",
        "\n",
        "        if batch_size <= 0:\n",
        "            raise ValueError(\"batch_size must be positive\")\n",
        "\n",
        "        n_samples = len(X_test)\n",
        "        n_batches = (n_samples + batch_size - 1) // batch_size\n",
        "        total_accuracy = 0\n",
        "\n",
        "        try:\n",
        "            for batch in range(n_batches):\n",
        "                start_idx = batch * batch_size\n",
        "                end_idx = min((batch + 1) * batch_size, n_samples)\n",
        "\n",
        "                x_batch = X_test[start_idx:end_idx]\n",
        "                y_batch = y_test[start_idx:end_idx]\n",
        "\n",
        "                output, conv1_output, pool1_output, fc1_output = self.forward(x_batch)\n",
        "\n",
        "                batch_accuracy = self.compute_accuracy(output, y_batch)\n",
        "                total_accuracy += batch_accuracy * len(x_batch)\n",
        "\n",
        "                self._free_gpu_memory(\n",
        "                    conv1_output, pool1_output,\n",
        "                    fc1_output, output\n",
        "                )\n",
        "\n",
        "            return total_accuracy / n_samples\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Evaluation failed: {str(e)}\")\n",
        "\n",
        "    def predict(self, X, batch_size=24):\n",
        "        \"\"\"\n",
        "        Generate predictions for input data.\n",
        "\n",
        "        Args:\n",
        "            X: Input data\n",
        "            batch_size: Size of mini-batches (default: 24)\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Predicted class labels\n",
        "        \"\"\"\n",
        "        if batch_size <= 0:\n",
        "            raise ValueError(\"batch_size must be positive\")\n",
        "\n",
        "        n_samples = len(X)\n",
        "        n_batches = (n_samples + batch_size - 1) // batch_size\n",
        "        predictions = np.zeros(n_samples, dtype=np.int32)\n",
        "\n",
        "        try:\n",
        "            for batch in range(n_batches):\n",
        "                start_idx = batch * batch_size\n",
        "                end_idx = min((batch + 1) * batch_size, n_samples)\n",
        "\n",
        "                x_batch = X[start_idx:end_idx]\n",
        "                output, conv1_output, pool1_output, fc1_output = self.forward(x_batch)\n",
        "\n",
        "                batch_predictions = np.argmax(output.get(), axis=1)\n",
        "                predictions[start_idx:end_idx] = batch_predictions\n",
        "\n",
        "                self._free_gpu_memory(\n",
        "                    conv1_output, pool1_output,\n",
        "                    fc1_output, output\n",
        "                )\n",
        "\n",
        "            return predictions\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Prediction failed: {str(e)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-12T21:48:42.709136Z",
          "iopub.execute_input": "2024-11-12T21:48:42.709563Z",
          "iopub.status.idle": "2024-11-12T21:48:42.767538Z",
          "shell.execute_reply.started": "2024-11-12T21:48:42.709530Z",
          "shell.execute_reply": "2024-11-12T21:48:42.766518Z"
        },
        "id": "AUpuqQHZuAn5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = CNN(learning_rate=0.01)\n",
        "\n",
        "cnn.train(X_train, y_train, X_test, y_test, epochs=10, batch_size=24)\n",
        "test_accuracy = cnn.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy :- {test_accuracy}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-12T21:49:31.853088Z",
          "iopub.execute_input": "2024-11-12T21:49:31.854215Z",
          "iopub.status.idle": "2024-11-12T21:49:31.881086Z",
          "shell.execute_reply.started": "2024-11-12T21:49:31.854172Z",
          "shell.execute_reply": "2024-11-12T21:49:31.880180Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaIQSF_6uAn6",
        "outputId": "2d5c4561-5cf8-44d1-e31b-e6d8c7f5c0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 362.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Accuracy: 0.3333 - Val Accuracy: 0.3333\n",
            "Epoch 2 - Accuracy: 0.3333 - Val Accuracy: 0.3333\n",
            "Epoch 3 - Accuracy: 0.3333 - Val Accuracy: 0.3333\n",
            "Epoch 4 - Accuracy: 0.3333 - Val Accuracy: 0.3333\n",
            "Epoch 5 - Accuracy: 0.3333 - Val Accuracy: 0.3333\n",
            "Epoch 6 - Accuracy: 0.3333 - Val Accuracy: 0.3333\n",
            "Epoch 7 - Accuracy: 0.3333 - Val Accuracy: 0.3333\n",
            "Epoch 8 - Accuracy: 0.3333 - Val Accuracy: 0.3333\n",
            "Epoch 9 - Accuracy: 0.3333 - Val Accuracy: 0.3333\n",
            "Epoch 10 - Accuracy: 0.3333 - Val Accuracy: 0.3333\n",
            "Test Accuracy :- 0.3333333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": null
    }
  ]
}